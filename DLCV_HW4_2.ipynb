{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ftag4T7Xof_K"
      },
      "outputs": [],
      "source": [
        "! /opt/bin/nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pK36nunY4eUY"
      },
      "outputs": [],
      "source": [
        "! git clone https://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@github.com/DLCV-Fall-2021/hw4-SonicBenz0408.git\n",
        "! bash ./hw4-SonicBenz0408/get_dataset.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GMO4LmfFDx_"
      },
      "outputs": [],
      "source": [
        "! pip install -r /content/hw4-SonicBenz0408/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6oxhq9Z426g"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def same_seeds(seed):\n",
        "    # Python built-in random module\n",
        "    random.seed(seed)\n",
        "    # Numpy\n",
        "    np.random.seed(seed)\n",
        "    # Torch\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "same_seeds(7414)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Re37W6DC9F4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.utils.data.sampler import Sampler\n",
        "\n",
        "import csv\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "from PIL import Image\n",
        "filenameToPILImage = lambda x: Image.open(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzfcASg_9yur"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms.transforms import RandomHorizontalFlip\n",
        "# mini-Imagenet dataset\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, csv_path, data_dir):\n",
        "        self.data_dir = data_dir\n",
        "        self.data_df = pd.read_csv(csv_path).set_index(\"id\")\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            filenameToPILImage,\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Resize((128, 128)),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "            ])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        path = self.data_df.loc[index, \"filename\"]\n",
        "        label = self.data_df.loc[index, \"label\"]\n",
        "        image = self.transform(os.path.join(self.data_dir, path))\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_df)\n",
        "\n",
        "class L_ImageDataset(Dataset):\n",
        "    def __init__(self, csv_path, data_dir, label_dict):\n",
        "        self.data_dir = data_dir\n",
        "        self.data_df = pd.read_csv(csv_path).set_index(\"id\")\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            filenameToPILImage,\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ColorJitter(0.2),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Resize((128, 128)),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "            ])\n",
        "        \n",
        "        self.label_dict = label_dict\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        path = self.data_df.loc[index, \"filename\"]\n",
        "        label = self.data_df.loc[index, \"label\"]\n",
        "        image = self.transform(os.path.join(self.data_dir, path))\n",
        "        return image, label_dict[label]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIYghreeoU-8"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5P8LGV5EBke"
      },
      "outputs": [],
      "source": [
        "! pip install byol-pytorch\n",
        "from byol_pytorch import BYOL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P37_M-JXDbjT"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "n_epoch = 700\n",
        "lr = 0.1\n",
        "\n",
        "model = torchvision.models.resnet50(pretrained=False)\n",
        "model.cuda()\n",
        "\n",
        "aug_fn = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomAffine(20, (0.1, 0.1), (1.0, 1.3)),\n",
        "    transforms.ColorJitter(0.2)\n",
        "])\n",
        "\n",
        "learner = BYOL(\n",
        "    model,\n",
        "    image_size = 128,\n",
        "    hidden_layer = 'avgpool',\n",
        "    augment_fn = aug_fn,\n",
        ")\n",
        "\n",
        "optimizer = torch.optim.Adam(learner.parameters(), lr=lr)\n",
        "\n",
        "pretrain_data_dir = \"/content/hw4_data/mini/train\"\n",
        "pretrain_csv = \"/content/hw4_data/mini/train.csv\"\n",
        "\n",
        "finetune_data_dir = \"/content/hw4_data/office/train\"\n",
        "finetune_csv = \"/content/hw4_data/office/train.csv\"\n",
        "\n",
        "val_data_dir = \"/content/hw4_data/office/val\"\n",
        "val_csv = \"/content/hw4_data/office/val.csv\"\n",
        "\n",
        "pretrain_dataset = ImageDataset(pretrain_csv, pretrain_data_dir)\n",
        "finetune_dataset = ImageDataset(finetune_csv, finetune_data_dir)\n",
        "\n",
        "pretrain_loader = DataLoader(pretrain_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "finetune_loader = DataLoader(pretrain_dataset, batch_size=64, shuffle=True, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UZnK6PeOLYW"
      },
      "outputs": [],
      "source": [
        "model.train()\n",
        "for epoch in range(n_epoch):\n",
        "    train_loss = 0.\n",
        "    for images, _ in tqdm(pretrain_loader, position=0, leave=True):\n",
        "        images = images.cuda()\n",
        "        loss = learner(images)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        learner.update_moving_average()\n",
        "        train_loss += loss\n",
        "\n",
        "    train_loss /= len(pretrain_loader)\n",
        "    print(f'epoch {epoch+1}, loss = {train_loss:.4f}')\n",
        "    torch.save(model.state_dict(), './drive/MyDrive/Hw4/pre_model_1e1.ckpt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKWx-hvK06IV"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "n_epoch = 300\n",
        "lr = 1e-3\n",
        "\n",
        "# loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = torchvision.models.resnet50(pretrained=False)\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(2048, 65),\n",
        ")\n",
        "#model.load_state_dict(torch.load('./drive/MyDrive/Hw4/pre_model_s13_3e3.ckpt'), strict=False)\n",
        "model.load_state_dict(torch.load('/content/hw4_data/pretrain_model_SL.pt'), strict=False)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "model.cuda()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "finetune_data_dir = \"/content/hw4_data/office/train\"\n",
        "finetune_csv = \"/content/hw4_data/office/train.csv\"\n",
        "\n",
        "val_data_dir = \"/content/hw4_data/office/val\"\n",
        "val_csv = \"/content/hw4_data/office/val.csv\"\n",
        "\n",
        "finetune_dataset = L_ImageDataset(finetune_csv, finetune_data_dir, label_dict)\n",
        "finetune_dataset, f_val_dataset = torch.utils.data.random_split(finetune_dataset, [3400, 551])\n",
        "finetune_loader = DataLoader(finetune_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
        "f_val_loader = DataLoader(f_val_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
        "val_dataset = L_ImageDataset(val_csv, val_data_dir, label_dict)\n",
        "\n",
        "#sch = torch.optim.lr_scheduler.LinearLR(optimizer, 1.0, 0.01, total_iters=len(finetune_loader)*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrOVnCejENmT"
      },
      "outputs": [],
      "source": [
        "print(label_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFp-dOqp6miJ"
      },
      "outputs": [],
      "source": [
        "label_dict = {}\n",
        "key = 0\n",
        "for image, label in finetune_dataset:\n",
        "    try:\n",
        "        if(label_dict[label]):\n",
        "            pass\n",
        "    except:\n",
        "        label_dict[label] = key\n",
        "        key += 1\n",
        "        if key == 65:\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AIqCOKWE3bJJ"
      },
      "outputs": [],
      "source": [
        "best_acc = 0.\n",
        "\n",
        "for epoch in range(n_epoch):\n",
        "    train_loss, val_loss, val_acc = 0., 0., 0.\n",
        "\n",
        "    model.train()\n",
        "    for images, labels in finetune_loader:\n",
        "        images, labels = images.cuda(), labels.cuda()\n",
        "        logits = model(images)\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        #sch.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for images, labels in f_val_loader:\n",
        "            images, labels = images.cuda(), labels.cuda()\n",
        "            logits = model(images)\n",
        "            loss = criterion(logits, labels)\n",
        "            acc = (logits.argmax(dim=-1) == labels).float().mean()\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            val_acc += acc\n",
        "\n",
        "\n",
        "    train_loss /= len(finetune_loader)\n",
        "    val_loss /= len(f_val_loader)\n",
        "    val_acc /= len(f_val_loader)\n",
        "    \n",
        "    print(f'epoch {epoch+1}, t_loss = {train_loss:.4f}, v_loss = {val_loss:.4f}, acc = {val_acc:.4f}')\n",
        "    if val_acc > best_acc :\n",
        "        best_acc = val_acc\n",
        "        print(f\"\\nsave model with acc = {best_acc:.5f}\")\n",
        "        torch.save(model.state_dict(), './drive/MyDrive/Hw4/model_D.ckpt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2uq0MMZxss0"
      },
      "outputs": [],
      "source": [
        "model = torchvision.models.resnet50(pretrained=False)\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(2048, 65),\n",
        ")\n",
        "\n",
        "model.load_state_dict(torch.load('./drive/MyDrive/Hw4/model_D.ckpt'))\n",
        "\n",
        "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=2)\n",
        "\n",
        "model.cuda().eval()\n",
        "\n",
        "count = 0\n",
        "pred_list = []\n",
        "with torch.no_grad():\n",
        "    for images, labels in tqdm(val_loader, position=0, leave=True):\n",
        "        images, labels = images.cuda(), labels.cuda()\n",
        "        logits = model(images)\n",
        "        pred = logits.argmax(dim=-1).int().item()\n",
        "        pred_list.append(pred)\n",
        "        if pred == labels :\n",
        "            count += 1\n",
        "final_acc = count / len(val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYim_e5UzDb2"
      },
      "outputs": [],
      "source": [
        "print(final_acc)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "name": "DLCV_HW4-2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}