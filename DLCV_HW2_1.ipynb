{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DLCV_HW2-1",
      "provenance": [],
      "collapsed_sections": [
        "XkvZ4JgCHCZD"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "946IpL6UsINt"
      },
      "source": [
        "! /opt/bin/nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7y4wyYdEABR"
      },
      "source": [
        "### Dataset Download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RetEOmCqu-8O"
      },
      "source": [
        "! git clone https://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@github.com/DLCV-Fall-2021/hw2-SonicBenz0408.git\n",
        "! bash ./hw2-SonicBenz0408/get_dataset.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjfM46dtmxXj"
      },
      "source": [
        "## Random seed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWuecW1imz42"
      },
      "source": [
        "import random\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def same_seeds(seed):\n",
        "    # Python built-in random module\n",
        "    random.seed(seed)\n",
        "    # Numpy\n",
        "    np.random.seed(seed)\n",
        "    # Torch\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "same_seeds(7414)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCTPz2iRQmwe"
      },
      "source": [
        "## Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TC8RRsX0QhL-"
      },
      "source": [
        "# Training progress bar\n",
        "!pip install -q qqdm\n",
        "\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils import spectral_norm\n",
        "import matplotlib.pyplot as plt\n",
        "from qqdm.notebook import qqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYjZ_G83_YX4"
      },
      "source": [
        "## Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZ6d0_cr8R26"
      },
      "source": [
        "class ImgDataset(Dataset):\n",
        "    def __init__(self, path, transform):\n",
        "        self.path = path\n",
        "        self.fnames = os.listdir(self.path)\n",
        "        self.transform = transform\n",
        "        self.num_samples = len(self.fnames)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        fname = os.path.join(self.path, self.fnames[idx])\n",
        "        img = torchvision.io.read_image(fname)\n",
        "        img = self.transform(img)\n",
        "        return img\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34mVNtHn7cwF"
      },
      "source": [
        "tfm = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomHorizontalFlip(0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "train_path = \"/content/hw2_data/face/train/\"\n",
        "train_set = ImgDataset(train_path, tfm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhxUjRUuHdti"
      },
      "source": [
        "images = [(train_set[i]+1)/2 for i in range(100)]\n",
        "grid_img = torchvision.utils.make_grid(images, nrow=10)\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(grid_img.permute(1, 2, 0))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkvZ4JgCHCZD"
      },
      "source": [
        "## Model (FID 34 IS 1.96)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0I1jRd6HFmm"
      },
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, resample):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.resample = resample\n",
        "        self.leaky_relu = nn.LeakyReLU(0.2, inplace=True)\n",
        "        if resample == 'down':\n",
        "            self.conv_shortcut = nn.Sequential(\n",
        "                spectral_norm(nn.Conv2d(input_dim, output_dim, 5, 2, 2)),\n",
        "                #nn.AvgPool2d(2, 2)\n",
        "            )\n",
        "            self.conv_1 = nn.Sequential(\n",
        "                spectral_norm(nn.Conv2d(input_dim, input_dim, 3, 1, 1)),\n",
        "                nn.LeakyReLU(0.2, inplace=True)\n",
        "            )\n",
        "            self.conv_2 = nn.Sequential(\n",
        "                spectral_norm(nn.Conv2d(input_dim, output_dim, 5, 2, 2)),\n",
        "            )\n",
        "        elif resample == 'up':\n",
        "            self.conv_shortcut = nn.Sequential(\n",
        "                #nn.Upsample(scale_factor=2),\n",
        "                #nn.Conv2d(input_dim, output_dim, 3, 1, 1)\n",
        "                nn.ConvTranspose2d(input_dim, output_dim, 5, 2, 2, 1),\n",
        "                \n",
        "            )\n",
        "            self.conv_1 = nn.Sequential(\n",
        "                nn.Conv2d(input_dim, output_dim, 3, 1, 1),\n",
        "                nn.BatchNorm2d(output_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout2d(0.5)\n",
        "            )\n",
        "            self.conv_2 = nn.Sequential(\n",
        "                nn.ConvTranspose2d(output_dim, output_dim, 5, 2, 2, 1),\n",
        "                nn.BatchNorm2d(output_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout2d(0.5)\n",
        "            )\n",
        "        elif resample==None:\n",
        "            self.conv_shortcut = spectral_norm(nn.Conv2d(input_dim, output_dim, 3, 1, 1))\n",
        "            self.conv_1 = nn.Sequential(\n",
        "                spectral_norm(nn.Conv2d(input_dim, output_dim, 3, 1, 1)),\n",
        "                nn.BatchNorm2d(output_dim),\n",
        "                nn.LeakyReLU(0.2, inplace=True)\n",
        "            )\n",
        "            self.conv_2 = nn.Sequential(\n",
        "                spectral_norm(nn.Conv2d(output_dim, output_dim, 3, 1, 1)),\n",
        "                nn.BatchNorm2d(output_dim),\n",
        "                nn.LeakyReLU(0.2, inplace=True)\n",
        "            )\n",
        "\n",
        "    def forward(self, input):\n",
        "        shortcut = self.conv_shortcut(input)\n",
        "        output = input\n",
        "        output = self.conv_1(output)\n",
        "        output = self.conv_2(output)\n",
        "\n",
        "        if self.input_dim != 8 * 64 and self.resample == \"down\":\n",
        "            output = self.leaky_relu(output)\n",
        "\n",
        "        return shortcut + output\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, in_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.dim = 64\n",
        "        self.ln1 = nn.Linear(in_dim, self.dim * 8 * 4 * 4)\n",
        "        self.rb1 = ResidualBlock(8 * self.dim, 8 * self.dim, resample = 'up')\n",
        "        self.rb2 = ResidualBlock(8 * self.dim, 4 * self.dim, resample = 'up')\n",
        "        self.rb3 = ResidualBlock(4 * self.dim, 2 * self.dim, resample = 'up')\n",
        "        self.rb4 = ResidualBlock(2 * self.dim, 1 * self.dim, resample = 'up')\n",
        "\n",
        "        self.conv_f = nn.Sequential(\n",
        "            nn.Conv2d(self.dim, 3, 3, 1, 1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "    \n",
        "    def forward(self, input):\n",
        "        output = self.ln1(input)\n",
        "        output = output.view(-1, 8 * self.dim, 4, 4)\n",
        "        output = self.rb1(output)\n",
        "        output = self.rb2(output)\n",
        "        output = self.rb3(output)\n",
        "        output = self.rb4(output)\n",
        "\n",
        "        output = self.conv_f(output)\n",
        "        return output\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self, in_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.dim = 64\n",
        "        self.rb1 = ResidualBlock(3, self.dim, resample = 'down')\n",
        "        self.rb2 = ResidualBlock(self.dim, 2 * self.dim, resample = 'down')\n",
        "        self.rb3 = ResidualBlock(2 * self.dim, 4 * self.dim, resample = 'down')\n",
        "        self.rb4 = ResidualBlock(4 * self.dim, 8 * self.dim, resample = 'down')\n",
        "        self.rb5 = ResidualBlock(8 * self.dim, 8 * self.dim, resample = 'down')\n",
        "        #self.pool_f = nn.AvgPool2d(8, 8)\n",
        "        self.ln1 = nn.Linear(self.dim * 8, 1)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = input\n",
        "        output = self.rb1(output)\n",
        "        output = self.rb2(output)\n",
        "        output = self.rb3(output)\n",
        "        output = self.rb4(output)\n",
        "        output = self.rb5(output)\n",
        "        #output = self.pool_f(output)\n",
        "        output = output.view(-1, self.dim * 8)\n",
        "        output = self.ln1(output)\n",
        "        return output\n",
        "\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hv6TCUpOJb4y"
      },
      "source": [
        "## Model FID 32.6 IS 1.9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ya1q5hTWJZE0"
      },
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, resample):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.resample = resample\n",
        "        self.leaky_relu = nn.LeakyReLU(0.2, inplace=True)\n",
        "        if resample == 'down':\n",
        "            self.conv_shortcut = nn.Sequential(\n",
        "                spectral_norm(nn.Conv2d(input_dim, output_dim, 5, 2, 2)),\n",
        "                #nn.AvgPool2d(2, 2)\n",
        "            )\n",
        "            self.conv_1 = nn.Sequential(\n",
        "                spectral_norm(nn.Conv2d(input_dim, input_dim, 3, 1, 1)),\n",
        "                nn.LeakyReLU(0.2, inplace=True)\n",
        "            )\n",
        "            self.conv_2 = nn.Sequential(\n",
        "                spectral_norm(nn.Conv2d(input_dim, output_dim, 5, 2, 2)),\n",
        "            )\n",
        "        elif resample == 'up':\n",
        "            self.conv_shortcut = nn.Sequential(\n",
        "                #nn.Upsample(scale_factor=2),\n",
        "                #nn.Conv2d(input_dim, output_dim, 3, 1, 1)\n",
        "                nn.ConvTranspose2d(input_dim, output_dim, 5, 2, 2, 1),\n",
        "                \n",
        "            )\n",
        "            self.conv_1 = nn.Sequential(\n",
        "                nn.Conv2d(input_dim, output_dim, 3, 1, 1),\n",
        "                nn.BatchNorm2d(output_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout2d(0.5)\n",
        "            )\n",
        "            self.conv_2 = nn.Sequential(\n",
        "                nn.ConvTranspose2d(output_dim, output_dim, 5, 2, 2, 1),\n",
        "                nn.BatchNorm2d(output_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout2d(0.5)\n",
        "            )\n",
        "        elif resample==None:\n",
        "            self.conv_shortcut = spectral_norm(nn.Conv2d(input_dim, output_dim, 3, 1, 1))\n",
        "            self.conv_1 = nn.Sequential(\n",
        "                spectral_norm(nn.Conv2d(input_dim, output_dim, 3, 1, 1)),\n",
        "                nn.BatchNorm2d(output_dim),\n",
        "                nn.LeakyReLU(0.2, inplace=True)\n",
        "            )\n",
        "            self.conv_2 = nn.Sequential(\n",
        "                spectral_norm(nn.Conv2d(output_dim, output_dim, 3, 1, 1)),\n",
        "                nn.BatchNorm2d(output_dim),\n",
        "                nn.LeakyReLU(0.2, inplace=True)\n",
        "            )\n",
        "\n",
        "    def forward(self, input):\n",
        "        shortcut = self.conv_shortcut(input)\n",
        "        output = input\n",
        "        output = self.conv_1(output)\n",
        "        output = self.conv_2(output)\n",
        "\n",
        "        if self.input_dim != 8 * 64 and self.resample == \"down\":\n",
        "            output = self.leaky_relu(output)\n",
        "\n",
        "        return shortcut + output\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, in_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.dim = 64\n",
        "        self.ln1 = nn.Linear(in_dim, self.dim * 16 * 4 * 4)\n",
        "        self.rb1 = ResidualBlock(16 * self.dim, 8 * self.dim, resample = 'up')\n",
        "        self.rb2 = ResidualBlock(8 * self.dim, 4 * self.dim, resample = 'up')\n",
        "        self.rb3 = ResidualBlock(4 * self.dim, 2 * self.dim, resample = 'up')\n",
        "        self.rb4 = ResidualBlock(2 * self.dim, 1 * self.dim, resample = 'up')\n",
        "\n",
        "        self.conv_f = nn.Sequential(\n",
        "            nn.Conv2d(self.dim, 3, 3, 1, 1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "    \n",
        "    def forward(self, input):\n",
        "        output = self.ln1(input)\n",
        "        output = output.view(-1, 16 * self.dim, 4, 4)\n",
        "        output = self.rb1(output)\n",
        "        output = self.rb2(output)\n",
        "        output = self.rb3(output)\n",
        "        output = self.rb4(output)\n",
        "\n",
        "        output = self.conv_f(output)\n",
        "        return output\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self, in_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.dim = 64\n",
        "        self.rb1 = ResidualBlock(3, self.dim, resample = 'down')\n",
        "        self.rb2 = ResidualBlock(self.dim, 2 * self.dim, resample = 'down')\n",
        "        self.rb3 = ResidualBlock(2 * self.dim, 4 * self.dim, resample = 'down')\n",
        "        self.rb4 = ResidualBlock(4 * self.dim, 8 * self.dim, resample = 'down')\n",
        "        self.rb5 = ResidualBlock(8 * self.dim, 16 * self.dim, resample = 'down')\n",
        "        #self.pool_f = nn.AvgPool2d(8, 8)\n",
        "        self.ln1 = nn.Linear(self.dim * 16, 1)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = input\n",
        "        output = self.rb1(output)\n",
        "        output = self.rb2(output)\n",
        "        output = self.rb3(output)\n",
        "        output = self.rb4(output)\n",
        "        output = self.rb5(output)\n",
        "        #output = self.pool_f(output)\n",
        "        output = output.view(-1, self.dim * 16)\n",
        "        output = self.ln1(output)\n",
        "        return output\n",
        "\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-kGJ0dG8SZN"
      },
      "source": [
        "## My model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GTLdFVtyurc"
      },
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, resample):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.resample = resample\n",
        "        self.leaky_relu = nn.LeakyReLU(0.2, inplace=True)\n",
        "        if resample == 'down':\n",
        "            self.conv_shortcut = nn.Sequential(\n",
        "                spectral_norm(nn.Conv2d(input_dim, output_dim, 5, 2, 2)),\n",
        "                #nn.AvgPool2d(2, 2)\n",
        "            )\n",
        "            self.conv_1 = nn.Sequential(\n",
        "                spectral_norm(nn.Conv2d(input_dim, input_dim, 3, 1, 1)),\n",
        "                nn.LeakyReLU(0.2, inplace=True)\n",
        "            )\n",
        "            self.conv_2 = nn.Sequential(\n",
        "                spectral_norm(nn.Conv2d(input_dim, output_dim, 5, 2, 2)),\n",
        "            )\n",
        "        elif resample == 'up':\n",
        "            self.conv_shortcut = nn.Sequential(\n",
        "                #nn.Upsample(scale_factor=2),\n",
        "                #nn.Conv2d(input_dim, output_dim, 3, 1, 1)\n",
        "                nn.ConvTranspose2d(input_dim, output_dim, 5, 2, 2, 1),\n",
        "                \n",
        "            )\n",
        "            self.conv_1 = nn.Sequential(\n",
        "                nn.Conv2d(input_dim, output_dim, 3, 1, 1),\n",
        "                nn.BatchNorm2d(output_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout2d(0.5)\n",
        "            )\n",
        "            self.conv_2 = nn.Sequential(\n",
        "                nn.ConvTranspose2d(output_dim, output_dim, 5, 2, 2, 1),\n",
        "                nn.BatchNorm2d(output_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout2d(0.5)\n",
        "            )\n",
        "        elif resample==None:\n",
        "            self.conv_shortcut = spectral_norm(nn.Conv2d(input_dim, output_dim, 3, 1, 1))\n",
        "            self.conv_1 = nn.Sequential(\n",
        "                spectral_norm(nn.Conv2d(input_dim, output_dim, 3, 1, 1)),\n",
        "                nn.BatchNorm2d(output_dim),\n",
        "                nn.LeakyReLU(0.2, inplace=True)\n",
        "            )\n",
        "            self.conv_2 = nn.Sequential(\n",
        "                spectral_norm(nn.Conv2d(output_dim, output_dim, 3, 1, 1)),\n",
        "                nn.BatchNorm2d(output_dim),\n",
        "                nn.LeakyReLU(0.2, inplace=True)\n",
        "            )\n",
        "\n",
        "    def forward(self, input):\n",
        "        shortcut = self.conv_shortcut(input)\n",
        "        output = input\n",
        "        output = self.conv_1(output)\n",
        "        output = self.conv_2(output)\n",
        "\n",
        "        if self.input_dim != 8 * 64 and self.resample == \"down\":\n",
        "            output = self.leaky_relu(output)\n",
        "\n",
        "        return shortcut + output\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, in_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.dim = 64\n",
        "        self.ln1 = nn.Linear(in_dim, self.dim * 16 * 4 * 4)\n",
        "        self.rb1 = ResidualBlock(16 * self.dim, 8 * self.dim, resample = 'up')\n",
        "        self.rb2 = ResidualBlock(8 * self.dim, 4 * self.dim, resample = 'up')\n",
        "        self.rb3 = ResidualBlock(4 * self.dim, 2 * self.dim, resample = 'up')\n",
        "        self.rb4 = ResidualBlock(2 * self.dim, 1 * self.dim, resample = 'up')\n",
        "\n",
        "        self.conv_f = nn.Sequential(\n",
        "            nn.Conv2d(self.dim, 3, 3, 1, 1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.apply(weights_init)\n",
        "    \n",
        "    def forward(self, input):\n",
        "        output = self.ln1(input)\n",
        "        output = output.view(-1, 16 * self.dim, 4, 4)\n",
        "        output = self.rb1(output)\n",
        "        output = self.rb2(output)\n",
        "        output = self.rb3(output)\n",
        "        output = self.rb4(output)\n",
        "\n",
        "        output = self.conv_f(output)\n",
        "        return output\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.dim = 64\n",
        "        self.rb1 = ResidualBlock(3, self.dim, resample = 'down')\n",
        "        self.rb2 = ResidualBlock(self.dim, 2 * self.dim, resample = 'down')\n",
        "        self.rb3 = ResidualBlock(2 * self.dim, 4 * self.dim, resample = 'down')\n",
        "        self.rb4 = ResidualBlock(4 * self.dim, 8 * self.dim, resample = 'down')\n",
        "        self.rb5 = ResidualBlock(8 * self.dim, 16 * self.dim, resample = 'down')\n",
        "        #self.pool_f = nn.AvgPool2d(8, 8)\n",
        "        self.ln1 = nn.Linear(self.dim * 16, 1)\n",
        "        self.apply(weights_init)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = input\n",
        "        output = self.rb1(output)\n",
        "        output = self.rb2(output)\n",
        "        output = self.rb3(output)\n",
        "        output = self.rb4(output)\n",
        "        output = self.rb5(output)\n",
        "        #output = self.pool_f(output)\n",
        "        output = output.view(-1, self.dim * 16)\n",
        "        output = self.ln1(output)\n",
        "        return output\n",
        "\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAMk_9Y8l09D"
      },
      "source": [
        "## Final Model (Summitted)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMANLFSHlznu"
      },
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, in_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        def dconv_bn_relu(in_dim, out_dim):\n",
        "            return nn.Sequential(\n",
        "                nn.ConvTranspose2d(in_dim, out_dim, 5, 2, padding=2, output_padding=1, bias=False),\n",
        "                nn.BatchNorm2d(out_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "            )\n",
        "\n",
        "        self.dim = 64\n",
        "        self.l1 = nn.Sequential(\n",
        "            nn.Linear(in_dim, self.dim * 8 * 4 * 4, bias=False),\n",
        "            nn.BatchNorm1d(self.dim * 8 * 4 * 4),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.l2_5 = nn.Sequential(\n",
        "            dconv_bn_relu(self.dim * 8, self.dim * 4),\n",
        "            dconv_bn_relu(self.dim * 4, self.dim * 2),\n",
        "            dconv_bn_relu(self.dim * 2, self.dim),\n",
        "            nn.ConvTranspose2d(self.dim, 3, 5, 2, padding=2, output_padding=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "        self.apply(weights_init)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.l1(x)\n",
        "        y = y.view(y.size(0), -1, 4, 4)\n",
        "        y = self.l2_5(y)\n",
        "        return y\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        def conv_lrelu(in_dim, out_dim):\n",
        "            return nn.Sequential(\n",
        "                spectral_norm(nn.Conv2d(in_dim, out_dim, 3, 1, 1)),\n",
        "                nn.LeakyReLU(0.2, inplace=True),\n",
        "                spectral_norm(nn.Conv2d(out_dim, out_dim, 5, 2, 2)),\n",
        "                nn.LeakyReLU(0.2, inplace=True),\n",
        "            )\n",
        "            \n",
        "        self.dim = 64\n",
        "\n",
        "        self.ls = nn.Sequential(\n",
        "            conv_lrelu(in_dim, self.dim),\n",
        "            conv_lrelu(self.dim, self.dim * 2),\n",
        "            conv_lrelu(self.dim * 2, self.dim * 4),\n",
        "            conv_lrelu(self.dim * 4, self.dim * 8),\n",
        "            spectral_norm(nn.Conv2d(self.dim * 8, 1, 4)),\n",
        "        )\n",
        "        self.apply(weights_init)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        y = self.ls(x)\n",
        "        y = y.view(-1)\n",
        "        return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cxo4teqaO5RJ"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5sCGIUtSViC"
      },
      "source": [
        "### Initialization\n",
        "- hyperparameters\n",
        "- model\n",
        "- optimizer\n",
        "- dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EqomOouHezf"
      },
      "source": [
        "# Training hyperparameters\n",
        "batch_size = 64\n",
        "z_dim = 128\n",
        "z_sample = Variable(torch.randn(100, z_dim)).cuda()\n",
        "lr = 2e-4\n",
        "\n",
        "n_epoch = 200\n",
        "n_critic = 1\n",
        "\n",
        "log_dir = os.path.join(\"/content/\", 'logs')\n",
        "ckpt_dir = os.path.join(\"/content/drive/MyDrive/Hw2/ckpt/\", 'checkpoints')\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "os.makedirs(ckpt_dir, exist_ok=True)\n",
        "\n",
        "# Model\n",
        "G = Generator(in_dim=z_dim).cuda()\n",
        "D = Discriminator(3).cuda()\n",
        "G.train()\n",
        "D.train()\n",
        "\n",
        "# Optimizer\n",
        "opt_D = torch.optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "opt_G = torch.optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "\n",
        "# DataLoader\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "sch_D = torch.optim.lr_scheduler.StepLR(opt_D, step_size=len(train_loader)*3, gamma=0.97)\n",
        "sch_G = torch.optim.lr_scheduler.StepLR(opt_G, step_size=len(train_loader)*3, gamma=0.97)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpJA1wzi0tii"
      },
      "source": [
        "### Training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GeDkuhR0sL8"
      },
      "source": [
        "steps = 0\n",
        "for e, epoch in enumerate(range(n_epoch)):\n",
        "    progress_bar = qqdm(train_loader)\n",
        "    for i, data in enumerate(progress_bar):\n",
        "        imgs = data\n",
        "        imgs = imgs.cuda()\n",
        "\n",
        "        bs = imgs.size(0)\n",
        "\n",
        "        #  Train D\n",
        "        \n",
        "        z = Variable(torch.randn(bs, z_dim)).cuda()\n",
        "        #sigma = 0.1 * (1 - (steps+1)/(len(train_loader)*n_epoch))\n",
        "        #noise_real = Variable(torch.randn(imgs.shape[0], imgs.shape[1], imgs.shape[2], imgs.shape[3])).cuda()\n",
        "        #noise_fake = Variable(torch.randn(imgs.shape[0], imgs.shape[1], imgs.shape[2], imgs.shape[3])).cuda()\n",
        "        r_imgs = Variable(imgs).cuda()# + noise_real * (sigma ** 0.5)\n",
        "        f_imgs = G(z)# + noise_fake * (sigma ** 0.5)\n",
        "\n",
        "        #hinge loss\n",
        "        d_loss_real = torch.nn.ReLU()(1.0 - D(r_imgs)).mean()\n",
        "        d_loss_fake = torch.nn.ReLU()(1.0 + D(f_imgs)).mean()\n",
        "        loss_D = d_loss_real + d_loss_fake\n",
        "\n",
        "        D.zero_grad()\n",
        "        loss_D.backward()\n",
        "        opt_D.step()\n",
        "        sch_D.step()\n",
        "\n",
        "#---------------------------------------------------------------------------------------------------------------\n",
        "        #  Train G\n",
        "        if steps % n_critic == 0:\n",
        "            # fake images\n",
        "            for p in D.parameters():\n",
        "                p.requires_grad = False\n",
        "            for p in G.parameters():\n",
        "                p.requires_grad = True\n",
        "            z = Variable(torch.randn(bs, z_dim)).cuda()\n",
        "            f_imgs = G(z)\n",
        "\n",
        "            loss_G = -torch.mean(D(f_imgs))\n",
        "\n",
        "            G.zero_grad()\n",
        "            loss_G.backward()\n",
        "\n",
        "            # Update the generator.\n",
        "            opt_G.step()\n",
        "            sch_G.step()\n",
        "            for p in D.parameters():\n",
        "                p.requires_grad = True\n",
        "            for p in G.parameters():\n",
        "                p.requires_grad = False\n",
        "\n",
        "        steps += 1\n",
        "        \n",
        "        progress_bar.set_infos({\n",
        "            'Loss_D': round(loss_D.item(), 4),\n",
        "            'Loss_G': round(loss_G.item(), 4),\n",
        "            'Epoch': e+1,\n",
        "            'Step': steps,\n",
        "        })\n",
        "\n",
        "    G.eval()\n",
        "    f_imgs_sample = (G(z_sample).data + 1) / 2.0\n",
        "    filename = os.path.join(log_dir, f'Epoch_{epoch+1:03d}.jpg')\n",
        "    torchvision.utils.save_image(f_imgs_sample, filename, nrow=10)\n",
        "    print(f' | Save some samples to {filename}.')\n",
        "    \n",
        "    G.train()\n",
        "\n",
        "    if (e+1) % 5 == 0 or e == 0:\n",
        "        # Save the checkpoints.\n",
        "        torch.save(G.state_dict(), os.path.join(ckpt_dir, 'G.pth'))\n",
        "        torch.save(D.state_dict(), os.path.join(ckpt_dir, 'D.pth'))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXPXcVD_HJB2"
      },
      "source": [
        "### Load model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JnQdNx2SUS2"
      },
      "source": [
        "import torch\n",
        "ckpt_dir = os.path.join(\"/content/drive/MyDrive/Hw2/ckpt/\", 'checkpoints')\n",
        "z_dim = 128\n",
        "G = Generator(z_dim)\n",
        "G.load_state_dict(torch.load(os.path.join(ckpt_dir, 'G_model.pth')))\n",
        "G.eval()\n",
        "G.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-I8PDocbHQiN"
      },
      "source": [
        "### Generate and show some images.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-SYKrRea_-Q"
      },
      "source": [
        "same_seeds(741)\n",
        "# Generate 1000 images and make a grid to save them.\n",
        "n_output = 250\n",
        "imgs_sample = torch.Tensor([]).cuda()\n",
        "for i in range(1000//n_output):\n",
        "    \n",
        "    z_sample = Variable(torch.randn(n_output, z_dim)).cuda()\n",
        "    imgs_sample = torch.cat((imgs_sample, (G(z_sample).data + 1) / 2.0))\n",
        "#log_dir = os.path.join(workspace_dir, 'logs')\n",
        "#filename = os.path.join(log_dir, 'result.jpg')\n",
        "#torchvision.utils.save_image(imgs_sample, filename, nrow=10)\n",
        "\n",
        "# Show 32 of the images.\n",
        "grid_img = torchvision.utils.make_grid(imgs_sample[:32].cpu(), nrow=8)\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(grid_img.permute(1, 2, 0))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbcmoTQpz_yf"
      },
      "source": [
        "# Save the generated images.\n",
        "os.makedirs('output', exist_ok=True)\n",
        "for i in range(1000):\n",
        "    torchvision.utils.save_image(imgs_sample[i], f'output/{i+1}.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofZQvzvbHTEE"
      },
      "source": [
        "! git clone https://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@github.com/DLCV-Fall-2021/hw2-SonicBenz0408.git\n",
        "! bash ./hw2-SonicBenz0408/get_dataset.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uhKCDR0HV4G"
      },
      "source": [
        "%cd hw2-SonicBenz0408/\n",
        "!bash ./hw2_p1.sh /content/output/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcYugQxz5hFJ"
      },
      "source": [
        "!pip install pytorch-fid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0SS69-o5jvB"
      },
      "source": [
        "! python -m pytorch_fid /content/hw2_data/face/test /content/output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTLQCI_l5txG"
      },
      "source": [
        "\"\"\"\n",
        "Usage: python3 IS.py --folder <path_to_the_folder_for_output_images>\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F\n",
        "import torch.utils.data\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torchvision.models.inception import inception_v3\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import entropy\n",
        "\n",
        "\n",
        "def inception_score(imgs, cuda=True, batch_size=32, resize=False, splits=1):\n",
        "    \"\"\"Computes the inception score of the generated images imgs\n",
        "    imgs -- Torch dataset of (3xHxW) numpy images normalized in the range [-1, 1]\n",
        "    cuda -- whether or not to run on GPU\n",
        "    batch_size -- batch size for feeding into Inception v3\n",
        "    splits -- number of splits\n",
        "    \"\"\"\n",
        "    N = len(imgs)\n",
        "\n",
        "    assert batch_size > 0\n",
        "    assert N > batch_size\n",
        "\n",
        "    # Set up dtype\n",
        "    if cuda:\n",
        "        dtype = torch.cuda.FloatTensor\n",
        "    else:\n",
        "        if torch.cuda.is_available():\n",
        "            print(\"WARNING: You have a CUDA device, so you should probably set cuda=True\")\n",
        "        dtype = torch.FloatTensor\n",
        "\n",
        "    # Set up dataloader\n",
        "    dataloader = torch.utils.data.DataLoader(imgs, batch_size=batch_size)\n",
        "\n",
        "    # Load inception model\n",
        "    inception_model = inception_v3(pretrained=True, transform_input=False).type(dtype)\n",
        "    inception_model.eval();\n",
        "    up = nn.Upsample(size=(299, 299), mode='bilinear').type(dtype)\n",
        "    def get_pred(x):\n",
        "        if resize:\n",
        "            x = up(x)\n",
        "        x = inception_model(x)\n",
        "        return F.softmax(x).data.cpu().numpy()\n",
        "\n",
        "    # Get predictions\n",
        "    preds = np.zeros((N, 1000))\n",
        "\n",
        "    for i, batch in enumerate(dataloader, 0):\n",
        "        batch = batch.type(dtype)\n",
        "        batchv = Variable(batch)\n",
        "        batch_size_i = batch.size()[0]\n",
        "\n",
        "        preds[i*batch_size:i*batch_size + batch_size_i] = get_pred(batchv)\n",
        "\n",
        "    # Now compute the mean kl-div\n",
        "    split_scores = []\n",
        "\n",
        "    for k in range(splits):\n",
        "        part = preds[k * (N // splits): (k+1) * (N // splits), :]\n",
        "        py = np.mean(part, axis=0)\n",
        "        scores = []\n",
        "        for i in range(part.shape[0]):\n",
        "            pyx = part[i, :]\n",
        "            scores.append(entropy(pyx, py))\n",
        "        split_scores.append(np.exp(np.mean(scores)))\n",
        "\n",
        "    return np.mean(split_scores), np.std(split_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ED8TKDV50oF"
      },
      "source": [
        "class GAN_Dataset(Dataset):\n",
        "    def __init__(self, filepath):\n",
        "        self.figsize = 64\n",
        "        self.images = []\n",
        "        self.file_list = os.listdir(filepath)\n",
        "        self.file_list.sort()\n",
        "\n",
        "        print(\"Load file from :\" ,filepath)\n",
        "        for i, file in enumerate(self.file_list):\n",
        "            print(\"\\r%d/%d\" %(i,len(self.file_list)),end = \"\")\n",
        "            img = Image.open(os.path.join(filepath, file)).convert('RGB')\n",
        "            self.images.append(img)\n",
        "        \n",
        "        print(\"\")\n",
        "        print(\"Loading file completed.\")\n",
        "        \n",
        "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5], [0.5])])\n",
        "        self.num_samples = len(self.images)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.transform(self.images[index])\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "\n",
        "train_dataset = GAN_Dataset(filepath = \"/content/output\")\n",
        "\n",
        "print (\"Calculating Inception Score...\")\n",
        "print (inception_score(train_dataset, cuda=True, batch_size=32, resize=True, splits=10))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}