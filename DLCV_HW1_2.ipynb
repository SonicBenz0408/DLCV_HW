{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DLCV_HW1-2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-0taGB7U_VG"
      },
      "source": [
        "! git clone https://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@github.com/DLCV-Fall-2021/hw1-SonicBenz0408.git\n",
        "! bash hw1-SonicBenz0408/get_dataset.sh\n",
        "\n",
        "# Import packages.\n",
        "import os\n",
        "import gc\n",
        "import glob\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models.utils import load_state_dict_from_url\n",
        "import imageio\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# This is for the progress bar.\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYs6fiqzY5wL"
      },
      "source": [
        "batch_size = 4\n",
        "\n",
        "voc_cls = {'urban':0, \n",
        "           'rangeland': 2,\n",
        "           'forest':3,  \n",
        "           'unknown':6,  \n",
        "           'barreb land':5,  \n",
        "           'Agriculture land':1,  \n",
        "           'water':4} \n",
        "cls_color = {\n",
        "    0:  [0, 255, 255],\n",
        "    1:  [255, 255, 0],\n",
        "    2:  [255, 0, 255],\n",
        "    3:  [0, 255, 0],\n",
        "    4:  [0, 0, 255],\n",
        "    5:  [255, 255, 255],\n",
        "    6: [0, 0, 0],\n",
        "}\n",
        "\n",
        "class SSDataset(Dataset):\n",
        "    def __init__(self, fnames):\n",
        "        self.fnames = fnames\n",
        "        self.num_samples = len(self.fnames)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        fname = self.fnames[idx]\n",
        "        # 1. Load the image\n",
        "        img = torchvision.io.read_image(fname) / 255\n",
        "        #img = size_tfm(img)\n",
        "        seg_path = fname[:-7] + \"mask.png\"\n",
        "        seg = imageio.imread(seg_path)\n",
        "        masks = np.zeros((512, 512))\n",
        "        mask = (seg >= 128).astype(int)\n",
        "        mask = 4 * mask[:, :, 0] + 2 * mask[:, :, 1] + mask[:, :, 2]\n",
        "        masks[mask == 3] = 0  # (Cyan: 011) Urban land \n",
        "        masks[mask == 6] = 1  # (Yellow: 110) Agriculture land \n",
        "        masks[mask == 5] = 2  # (Purple: 101) Rangeland \n",
        "        masks[mask == 2] = 3  # (Green: 010) Forest land \n",
        "        masks[mask == 1] = 4  # (Blue: 001) Water \n",
        "        masks[mask == 7] = 5  # (White: 111) Barren land \n",
        "        masks[mask == 0] = 6  # (Black: 000) Unknown \n",
        "\n",
        "        #masks = masks.long()\n",
        "        return img, masks\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "data_path = \"hw1_data/p2_data/\"\n",
        "\n",
        "train_fnames = glob.glob(os.path.join(os.path.join(data_path, \"train\"), '*.jpg'))\n",
        "\n",
        "train_set = SSDataset(train_fnames)\n",
        "train_set, val_set = torch.utils.data.random_split(train_set, [1800, 200])\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PJVnAs3hJXk"
      },
      "source": [
        "# VGG-16 FCN32 \n",
        "\n",
        "# reference: https://github.com/wkentaro/pytorch-fcn/blob/main/torchfcn/models/fcn32s.py\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Classifier, self).__init__()\n",
        "        \n",
        "        # conv1\n",
        "        self.conv1_1 = nn.Conv2d(3, 64, 3, 1, 1)\n",
        "        self.relu1_1 = nn.ReLU(inplace=True)\n",
        "        self.conv1_2 = nn.Conv2d(64, 64, 3, 1, 1)\n",
        "        self.relu1_2 = nn.ReLU(inplace=True)\n",
        "        self.pool1 = nn.MaxPool2d(2, stride=2)  # 1/2\n",
        "\n",
        "        # conv2\n",
        "        self.conv2_1 = nn.Conv2d(64, 128, 3, 1, 1)\n",
        "        self.relu2_1 = nn.ReLU(inplace=True)\n",
        "        self.conv2_2 = nn.Conv2d(128, 128, 3, 1, 1)\n",
        "        self.relu2_2 = nn.ReLU(inplace=True)\n",
        "        self.pool2 = nn.MaxPool2d(2, stride=2)  # 1/4\n",
        "\n",
        "        # conv3\n",
        "        self.conv3_1 = nn.Conv2d(128, 256, 3, 1, 1)\n",
        "        self.relu3_1 = nn.ReLU(inplace=True)\n",
        "        self.conv3_2 = nn.Conv2d(256, 256, 3, 1, 1)\n",
        "        self.relu3_2 = nn.ReLU(inplace=True)\n",
        "        self.conv3_3 = nn.Conv2d(256, 256, 3, 1, 1)\n",
        "        self.relu3_3 = nn.ReLU(inplace=True)\n",
        "        self.pool3 = nn.MaxPool2d(2, stride=2)  # 1/8\n",
        "\n",
        "        # conv4\n",
        "        self.conv4_1 = nn.Conv2d(256, 512, 3, 1, 1)\n",
        "        self.relu4_1 = nn.ReLU(inplace=True)\n",
        "        self.conv4_2 = nn.Conv2d(512, 512, 3, 1, 1)\n",
        "        self.relu4_2 = nn.ReLU(inplace=True)\n",
        "        self.conv4_3 = nn.Conv2d(512, 512, 3, 1, 1)\n",
        "        self.relu4_3 = nn.ReLU(inplace=True)\n",
        "        self.pool4 = nn.MaxPool2d(2, stride=2)  # 1/16\n",
        "\n",
        "        # conv5\n",
        "        self.conv5_1 = nn.Conv2d(512, 512, 3, 1, 1)\n",
        "        self.relu5_1 = nn.ReLU(inplace=True)\n",
        "        self.conv5_2 = nn.Conv2d(512, 512, 3, 1, 1)\n",
        "        self.relu5_2 = nn.ReLU(inplace=True)\n",
        "        self.conv5_3 = nn.Conv2d(512, 512, 3, 1, 1)\n",
        "        self.relu5_3 = nn.ReLU(inplace=True)\n",
        "        self.pool5 = nn.MaxPool2d(2, stride=2)  # 1/32\n",
        "\n",
        "\n",
        "        # fc6\n",
        "        self.fc6 = nn.Conv2d(512, 4096, 1)\n",
        "        self.relu6 = nn.ReLU(inplace=True)\n",
        "        self.drop6 = nn.Dropout2d()\n",
        "\n",
        "        # fc7\n",
        "        self.fc7 = nn.Conv2d(4096, 4096, 1)\n",
        "        self.relu7 = nn.ReLU(inplace=True)\n",
        "        self.drop7 = nn.Dropout2d()\n",
        "\n",
        "        self.score_fr = nn.Conv2d(4096, 7, 1)\n",
        "        self.upscore32 = nn.ConvTranspose2d(7, 7, 32, 32, bias=False)\n",
        "    \n",
        "    def copy_param_vgg16(self, vgg16):\n",
        "        \n",
        "        features = [\n",
        "            self.conv1_1, self.relu1_1,\n",
        "            self.conv1_2, self.relu1_2,\n",
        "            self.pool1,\n",
        "            self.conv2_1, self.relu2_1,\n",
        "            self.conv2_2, self.relu2_2,\n",
        "            self.pool2,\n",
        "            self.conv3_1, self.relu3_1,\n",
        "            self.conv3_2, self.relu3_2,\n",
        "            self.conv3_3, self.relu3_3,\n",
        "            self.pool3,\n",
        "            self.conv4_1, self.relu4_1,\n",
        "            self.conv4_2, self.relu4_2,\n",
        "            self.conv4_3, self.relu4_3,\n",
        "            self.pool4,\n",
        "            self.conv5_1, self.relu5_1,\n",
        "            self.conv5_2, self.relu5_2,\n",
        "            self.conv5_3, self.relu5_3,\n",
        "            self.pool5,\n",
        "        ]\n",
        "        \n",
        "        for l1, l2 in zip(vgg16.features, features):\n",
        "            if isinstance(l1, nn.Conv2d) and isinstance(l2, nn.Conv2d):\n",
        "                assert l1.weight.size() == l2.weight.size()\n",
        "                assert l1.bias.size() == l2.bias.size()\n",
        "                l2.weight.data = l1.weight.data\n",
        "                l2.bias.data = l1.bias.data\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = x\n",
        "        h = self.relu1_1(self.conv1_1(h))\n",
        "        h = self.relu1_2(self.conv1_2(h))\n",
        "        h = self.pool1(h)\n",
        "\n",
        "        h = self.relu2_1(self.conv2_1(h))\n",
        "        h = self.relu2_2(self.conv2_2(h))\n",
        "        h = self.pool2(h)\n",
        "\n",
        "        h = self.relu3_1(self.conv3_1(h))\n",
        "        h = self.relu3_2(self.conv3_2(h))\n",
        "        h = self.relu3_3(self.conv3_3(h))\n",
        "        h = self.pool3(h)\n",
        "        \n",
        "        h = self.relu4_1(self.conv4_1(h))\n",
        "        h = self.relu4_2(self.conv4_2(h))\n",
        "        h = self.relu4_3(self.conv4_3(h))\n",
        "        h = self.pool4(h)\n",
        "\n",
        "        h = self.relu5_1(self.conv5_1(h))\n",
        "        h = self.relu5_2(self.conv5_2(h))\n",
        "        h = self.relu5_3(self.conv5_3(h))\n",
        "        h = self.pool5(h)\n",
        "\n",
        "        h = self.relu6(self.fc6(h))\n",
        "        h = self.drop6(h)\n",
        "        h = self.relu7(self.fc7(h))\n",
        "        h = self.drop7(h)\n",
        "\n",
        "\n",
        "        h = self.score_fr(h)\n",
        "        h = self.upscore32(h)\n",
        "        #print(h.shape)\n",
        "\n",
        "        return h.float()\n",
        "\n",
        "\n",
        "def cross_entropy2d(input, target, weight=None, size_average=True):\n",
        "    # input: (n, c, h, w), target: (n, h, w)\n",
        "    n, c, h, w = input.size()\n",
        "    # log_p: (n, c, h, w)\n",
        "    log_p = F.log_softmax(input, dim=1)\n",
        "    # log_p: (n*h*w, c)\n",
        "    log_p = log_p.transpose(1, 2).transpose(2, 3).contiguous()\n",
        "    log_p = log_p[target.view(n, h, w, 1).repeat(1, 1, 1, c) >= 0]\n",
        "    log_p = log_p.view(-1, c)\n",
        "    # target: (n*h*w,)\n",
        "    mask = target >= 0\n",
        "    target = target[mask]\n",
        "    crit = nn.NLLLoss(weight=weight, reduction='sum')\n",
        "    loss = crit(log_p, target)\n",
        "    if size_average:\n",
        "        loss /= mask.data.sum()\n",
        "    return loss\n",
        "\n",
        "# fix random seed\n",
        "def same_seeds(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)  \n",
        "    np.random.seed(seed)  \n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7QvKMkYm509"
      },
      "source": [
        "# VGG-16 FCN8\n",
        "\n",
        "# reference: https://github.com/wkentaro/pytorch-fcn/blob/main/torchfcn/models/fcn32s.py\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Classifier, self).__init__()\n",
        "        \n",
        "        # conv1\n",
        "        self.conv1_1 = nn.Conv2d(3, 64, 3, 1, 1)\n",
        "        self.relu1_1 = nn.ReLU(inplace=True)\n",
        "        self.conv1_2 = nn.Conv2d(64, 64, 3, 1, 1)\n",
        "        self.relu1_2 = nn.ReLU(inplace=True)\n",
        "        self.pool1 = nn.MaxPool2d(2, stride=2)  # 1/2\n",
        "\n",
        "        # conv2\n",
        "        self.conv2_1 = nn.Conv2d(64, 128, 3, 1, 1)\n",
        "        self.relu2_1 = nn.ReLU(inplace=True)\n",
        "        self.conv2_2 = nn.Conv2d(128, 128, 3, 1, 1)\n",
        "        self.relu2_2 = nn.ReLU(inplace=True)\n",
        "        self.pool2 = nn.MaxPool2d(2, stride=2)  # 1/4\n",
        "\n",
        "        # conv3\n",
        "        self.conv3_1 = nn.Conv2d(128, 256, 3, 1, 1)\n",
        "        self.relu3_1 = nn.ReLU(inplace=True)\n",
        "        self.conv3_2 = nn.Conv2d(256, 256, 3, 1, 1)\n",
        "        self.relu3_2 = nn.ReLU(inplace=True)\n",
        "        self.conv3_3 = nn.Conv2d(256, 256, 3, 1, 1)\n",
        "        self.relu3_3 = nn.ReLU(inplace=True)\n",
        "        self.pool3 = nn.MaxPool2d(2, stride=2)  # 1/8\n",
        "\n",
        "        # conv4\n",
        "        self.conv4_1 = nn.Conv2d(256, 512, 3, 1, 1)\n",
        "        self.relu4_1 = nn.ReLU(inplace=True)\n",
        "        self.conv4_2 = nn.Conv2d(512, 512, 3, 1, 1)\n",
        "        self.relu4_2 = nn.ReLU(inplace=True)\n",
        "        self.conv4_3 = nn.Conv2d(512, 512, 3, 1, 1)\n",
        "        self.relu4_3 = nn.ReLU(inplace=True)\n",
        "        self.pool4 = nn.MaxPool2d(2, stride=2)  # 1/16\n",
        "\n",
        "        # conv5\n",
        "        self.conv5_1 = nn.Conv2d(512, 512, 3, 1, 1)\n",
        "        self.relu5_1 = nn.ReLU(inplace=True)\n",
        "        self.conv5_2 = nn.Conv2d(512, 512, 3, 1, 1)\n",
        "        self.relu5_2 = nn.ReLU(inplace=True)\n",
        "        self.conv5_3 = nn.Conv2d(512, 512, 3, 1, 1)\n",
        "        self.relu5_3 = nn.ReLU(inplace=True)\n",
        "        self.pool5 = nn.MaxPool2d(2, stride=2)  # 1/32\n",
        "\n",
        "\n",
        "        # fc6\n",
        "        self.fc6 = nn.Conv2d(512, 4096, 1)\n",
        "        self.relu6 = nn.ReLU(inplace=True)\n",
        "        self.drop6 = nn.Dropout2d()\n",
        "\n",
        "        # fc7\n",
        "        self.fc7 = nn.Conv2d(4096, 4096, 1)\n",
        "        self.relu7 = nn.ReLU(inplace=True)\n",
        "        self.drop7 = nn.Dropout2d()\n",
        "\n",
        "        self.score_fr = nn.Conv2d(4096, 7, 1)\n",
        "        self.score_pool3 = nn.Conv2d(256, 7, 1)\n",
        "        self.score_pool4 = nn.Conv2d(512, 7, 1)\n",
        "\n",
        "        self.upscore2 = nn.ConvTranspose2d(7, 7, 2, 2, bias=False)\n",
        "        self.upscore8 = nn.ConvTranspose2d(7, 7, 16, 8, bias=False)\n",
        "        self.up_pool4 = nn.ConvTranspose2d(7, 7, 2, 2, bias=False)\n",
        "    \n",
        "    def copy_param_vgg16(self, vgg16):\n",
        "        \n",
        "        features = [\n",
        "            self.conv1_1, self.relu1_1,\n",
        "            self.conv1_2, self.relu1_2,\n",
        "            self.pool1,\n",
        "            self.conv2_1, self.relu2_1,\n",
        "            self.conv2_2, self.relu2_2,\n",
        "            self.pool2,\n",
        "            self.conv3_1, self.relu3_1,\n",
        "            self.conv3_2, self.relu3_2,\n",
        "            self.conv3_3, self.relu3_3,\n",
        "            self.pool3,\n",
        "            self.conv4_1, self.relu4_1,\n",
        "            self.conv4_2, self.relu4_2,\n",
        "            self.conv4_3, self.relu4_3,\n",
        "            self.pool4,\n",
        "            self.conv5_1, self.relu5_1,\n",
        "            self.conv5_2, self.relu5_2,\n",
        "            self.conv5_3, self.relu5_3,\n",
        "            self.pool5,\n",
        "        ]\n",
        "        \n",
        "        for l1, l2 in zip(vgg16.features, features):\n",
        "            if isinstance(l1, nn.Conv2d) and isinstance(l2, nn.Conv2d):\n",
        "                assert l1.weight.size() == l2.weight.size()\n",
        "                assert l1.bias.size() == l2.bias.size()\n",
        "                l2.weight.data = l1.weight.data\n",
        "                l2.bias.data = l1.bias.data\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = x\n",
        "        h = self.relu1_1(self.conv1_1(h))\n",
        "        h = self.relu1_2(self.conv1_2(h))\n",
        "        h = self.pool1(h)\n",
        "\n",
        "        h = self.relu2_1(self.conv2_1(h))\n",
        "        h = self.relu2_2(self.conv2_2(h))\n",
        "        h = self.pool2(h)\n",
        "\n",
        "        h = self.relu3_1(self.conv3_1(h))\n",
        "        h = self.relu3_2(self.conv3_2(h))\n",
        "        h = self.relu3_3(self.conv3_3(h))\n",
        "        h = self.pool3(h)\n",
        "        temp1 = h\n",
        "\n",
        "        h = self.relu4_1(self.conv4_1(h))\n",
        "        h = self.relu4_2(self.conv4_2(h))\n",
        "        h = self.relu4_3(self.conv4_3(h))\n",
        "        h = self.pool4(h)\n",
        "        temp2 = h\n",
        "\n",
        "        h = self.relu5_1(self.conv5_1(h))\n",
        "        h = self.relu5_2(self.conv5_2(h))\n",
        "        h = self.relu5_3(self.conv5_3(h))\n",
        "        h = self.pool5(h)\n",
        "\n",
        "        h = self.relu6(self.fc6(h))\n",
        "        h = self.drop6(h)\n",
        "        h = self.relu7(self.fc7(h))\n",
        "        h = self.drop7(h)\n",
        "\n",
        "\n",
        "        h = self.score_fr(h)\n",
        "        h = self.upscore2(h)\n",
        "        upscore2 = h  # 1/16\n",
        "\n",
        "        h = self.score_pool4(temp2)\n",
        "        score_pool4c = h  # 1/16\n",
        "\n",
        "        h = upscore2 + score_pool4c\n",
        "        h = self.up_pool4(h)\n",
        "        upscore_pool4 = h\n",
        "\n",
        "        h = self.score_pool3(temp1)\n",
        "        score_pool3c = h\n",
        "\n",
        "        h = upscore_pool4 + score_pool3c\n",
        "\n",
        "        h = self.upscore8(h)\n",
        "        h = h[:, :, 4:4 + x.size()[2], 4:4 + x.size()[3]].contiguous()\n",
        "        return h.float()\n",
        "\n",
        "\n",
        "def cross_entropy2d(input, target, weight=None, size_average=True):\n",
        "    # input: (n, c, h, w), target: (n, h, w)\n",
        "    n, c, h, w = input.size()\n",
        "    # log_p: (n, c, h, w)\n",
        "    log_p = F.log_softmax(input, dim=1)\n",
        "    # log_p: (n*h*w, c)\n",
        "    log_p = log_p.transpose(1, 2).transpose(2, 3).contiguous()\n",
        "    log_p = log_p[target.view(n, h, w, 1).repeat(1, 1, 1, c) >= 0]\n",
        "    log_p = log_p.view(-1, c)\n",
        "    # target: (n*h*w,)\n",
        "    mask = target >= 0\n",
        "    target = target[mask]\n",
        "    crit = nn.NLLLoss(weight=weight, reduction='sum')\n",
        "    loss = crit(log_p, target)\n",
        "    if size_average:\n",
        "        loss /= mask.data.sum()\n",
        "    return loss\n",
        "\n",
        "# fix random seed\n",
        "def same_seeds(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)  \n",
        "    np.random.seed(seed)  \n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9XUYG5Mcz2E"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcNqWpC0iUCs"
      },
      "source": [
        "del model\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMx7ithWoPx2"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "#pretrained_weight = load_state_dict_from_url('https://download.pytorch.org/models/vgg16-397923af.pth')\n",
        "#pretrained_weight.pop('classifier.0.bias')\n",
        "#pretrained_weight.pop('classifier.0.weight')\n",
        "#pretrained_weight.pop('classifier.3.bias')\n",
        "#pretrained_weight.pop('classifier.3.weight')\n",
        "#pretrained_weight.pop('classifier.6.bias')\n",
        "#pretrained_weight.pop('classifier.6.weight')\n",
        "\n",
        "vgg16 = torchvision.models.vgg16(pretrained=True)\n",
        "# reproduce\n",
        "same_seeds(7414)\n",
        "\n",
        "path = \"/content/drive/MyDrive/model\"\n",
        "save_path = os.path.join(path, \"FCN8.ckpt\")\n",
        "\n",
        "model = Classifier().to(device)\n",
        "model.copy_param_vgg16(vgg16)\n",
        "model.to(device)\n",
        "#model.load_state_dict(torch.load(save_path))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
        "\n",
        "del vgg16\n",
        "gc.collect()\n",
        "\n",
        "# number of epoch\n",
        "n_epochs = 70\n",
        "accu_step = 1\n",
        "count = 0\n",
        "\n",
        "best_acc = 0.\n",
        "\n",
        "\n",
        "if not os.path.exists(path):\n",
        "    os.mkdir(path)\n",
        "\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    \n",
        "    # train\n",
        "    model.train()\n",
        "    \n",
        "\n",
        "    train_loss = []\n",
        "    train_accs = []\n",
        "\n",
        "    for batch in tqdm(train_loader):\n",
        "\n",
        "        imgs, labels = batch\n",
        "        imgs, labels = Variable(imgs, requires_grad=True), Variable(labels, requires_grad=True)\n",
        "        logits = model(imgs.to(device))\n",
        "        \n",
        "        loss = cross_entropy2d(logits, labels.to(device).long())\n",
        "\n",
        "        \n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the gradient norms for stable training.\n",
        "        # grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
        "\n",
        "        #if count % accu_step == 0:\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        count += 1\n",
        "        acc = (logits.argmax(dim=1) == labels.to(device)).float().mean()\n",
        "        \n",
        "        train_loss.append(loss.item())\n",
        "        train_accs.append(acc)\n",
        "\n",
        "    train_loss = sum(train_loss) / len(train_loss)\n",
        "    train_acc = sum(train_accs) / len(train_accs)\n",
        "\n",
        "    # print\n",
        "    print(f\"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n",
        "\n",
        "\n",
        "    # validation\n",
        "    model.eval()\n",
        "\n",
        "    valid_loss = []\n",
        "    valid_accs = []\n",
        "\n",
        "    for batch in tqdm(val_loader):\n",
        "\n",
        "        imgs, labels = batch\n",
        "        imgs, labels = imgs, labels\n",
        "        imgs, labels = Variable(imgs), Variable(labels)\n",
        "\n",
        "        with torch.no_grad():\n",
        "          logits = model(imgs.to(device))\n",
        "\n",
        "        loss = cross_entropy2d(logits, labels.to(device).long())\n",
        "        acc = (logits.argmax(dim=1) == labels.to(device)).float().mean()\n",
        "        valid_loss.append(loss.item())\n",
        "        valid_accs.append(acc)\n",
        "\n",
        "    valid_loss = sum(valid_loss) / len(valid_loss)\n",
        "    valid_acc = sum(valid_accs) / len(valid_accs)\n",
        "\n",
        "    if valid_acc > best_acc :\n",
        "      \n",
        "      best_acc = valid_acc\n",
        "      print(f\"\\nsave model with acc = {best_acc:.5f}\")\n",
        "      torch.save(model.state_dict(), save_path)\n",
        "\n",
        "    # print\n",
        "    print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2xjG8gWDwmB"
      },
      "source": [
        "! wget https://www.dropbox.com/s/r3fb651nv0p7jif/FCN8.ckpt?dl=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QB-ll6zNEsnp"
      },
      "source": [
        "test_fnames = glob.glob(os.path.join(os.path.join(data_path, \"validation\"), '*.jpg'))\n",
        "test_fnames.sort()\n",
        "test_set = SSDataset(test_fnames)\n",
        "test_loader = DataLoader(test_set, batch_size=1, shuffle=False, num_workers=2, pin_memory=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOb79lUkFJve"
      },
      "source": [
        "pred_path = \"./pred/\"\n",
        "pred_fnames = [pred_path + fname[-12:-8] + \".png\" for fname in test_fnames]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69i1F4zLARI9"
      },
      "source": [
        "if not os.path.exists(pred_path):\n",
        "    os.mkdir(pred_path)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "path = \"/content/drive/MyDrive/model\"\n",
        "#save_path = os.path.join(path, \"FCN8.ckpt\")\n",
        "save_path = \"/content/FCN8.ckpt\"\n",
        "model = Classifier().to(device)\n",
        "model.load_state_dict(torch.load(save_path))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "count = 0\n",
        "\n",
        "for batch in test_loader:\n",
        "\n",
        "    img, label = batch\n",
        "    img, label = img, label\n",
        "\n",
        "    img, label = Variable(img), Variable(label)\n",
        "    with torch.no_grad():\n",
        "        logit = model(img.to(device))\n",
        "\n",
        "    output = logit.argmax(dim=1)[0].tolist()\n",
        "\n",
        "    for i in range(512):\n",
        "        for j in range(512):\n",
        "            output[i][j] = cls_color[output[i][j]]\n",
        "\n",
        "    output = np.array(output)\n",
        "    imageio.imsave(pred_fnames[count], np.uint8(output))\n",
        "    count += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LczgCLHsVOy7"
      },
      "source": [
        "! python3 ./hw1-SonicBenz0408/mean_iou_evaluate.py -g ./hw1_data/p2_data/validation/ -p ./pred/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}