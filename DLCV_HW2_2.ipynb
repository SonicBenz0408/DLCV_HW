{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DLCV_HW2-2",
      "provenance": [],
      "collapsed_sections": [
        "H-kGJ0dG8SZN",
        "qeOBdd5s3-me"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7y4wyYdEABR"
      },
      "source": [
        "### Dataset Download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RetEOmCqu-8O"
      },
      "source": [
        "! git clone https://<token>@github.com/DLCV-Fall-2021/hw2-SonicBenz0408.git\n",
        "! bash ./hw2-SonicBenz0408/get_dataset.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjfM46dtmxXj"
      },
      "source": [
        "## Random seed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWuecW1imz42"
      },
      "source": [
        "import random\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def same_seeds(seed):\n",
        "    # Python built-in random module\n",
        "    random.seed(seed)\n",
        "    # Numpy\n",
        "    np.random.seed(seed)\n",
        "    # Torch\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "same_seeds(7414)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCTPz2iRQmwe"
      },
      "source": [
        "## Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TC8RRsX0QhL-"
      },
      "source": [
        "# Training progress bar\n",
        "!pip install -q qqdm\n",
        "\n",
        "import os\n",
        "import csv\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.nn.utils import spectral_norm\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from qqdm.notebook import qqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYjZ_G83_YX4"
      },
      "source": [
        "## Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZ6d0_cr8R26"
      },
      "source": [
        "class ImgDataset(Dataset):\n",
        "    def __init__(self, path, labels, transform):\n",
        "        self.path = path\n",
        "        self.fnames = os.listdir(self.path)\n",
        "        self.fnames.sort()\n",
        "        self.transform = transform\n",
        "        self.num_samples = len(self.fnames)\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        label = int(self.labels[idx])\n",
        "        fname = os.path.join(self.path, self.fnames[idx])\n",
        "        img = torchvision.io.read_image(fname)\n",
        "        img = self.transform(img)\n",
        "        return img, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34mVNtHn7cwF"
      },
      "source": [
        "tfm = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    #transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "    transforms.ColorJitter(brightness=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
        "])\n",
        "train_label_path = \"/content/hw2_data/digits/mnistm/train.csv\"\n",
        "train_label = []\n",
        "with open(train_label_path, \"r\") as f:\n",
        "    rows = csv.reader(f)\n",
        "    for row in rows:\n",
        "        train_label.append(row[-1])\n",
        "train_label.pop(0)\n",
        "\n",
        "train_path = \"/content/hw2_data/digits/mnistm/train/\"\n",
        "train_set = ImgDataset(train_path, train_label, tfm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhxUjRUuHdti"
      },
      "source": [
        "images = [(train_set[i][0]+1)/2 for i in range(25)]\n",
        "grid_img = torchvision.utils.make_grid(images, nrow=5)\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(grid_img.permute(1, 2, 0))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-kGJ0dG8SZN"
      },
      "source": [
        "## My model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEjbcfGWlrin"
      },
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, resample, last=False):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.resample = resample\n",
        "        self.leaky_relu = nn.LeakyReLU(0.2, inplace=True)\n",
        "        if resample == 'down':\n",
        "            self.conv_shortcut = nn.Sequential(\n",
        "                spectral_norm(nn.Conv2d(input_dim, output_dim, 3, 2, 1)),\n",
        "                #nn.AvgPool2d(2, 2, ceil_mode=True)\n",
        "            )\n",
        "            self.conv_1 = nn.Sequential(\n",
        "                spectral_norm(nn.Conv2d(input_dim, input_dim, 3, 1, 1)),\n",
        "                nn.LeakyReLU(0.2, inplace=True)\n",
        "            )\n",
        "            self.conv_2 = nn.Sequential(\n",
        "                spectral_norm(nn.Conv2d(input_dim, output_dim, 3, 2, 1)),\n",
        "            )\n",
        "        elif resample == 'up':\n",
        "            if not last:\n",
        "                self.conv_shortcut = nn.Sequential(\n",
        "                    #nn.Upsample(scale_factor=2),\n",
        "                    #nn.Conv2d(input_dim, output_dim, 3, 1, 1)\n",
        "                    nn.ConvTranspose2d(input_dim, output_dim, 5, 2, 0, 0),\n",
        "                    \n",
        "                )\n",
        "                self.conv_1 = nn.Sequential(\n",
        "                    nn.Conv2d(input_dim, output_dim, 3, 1, 1),\n",
        "                    nn.BatchNorm2d(output_dim),\n",
        "                    nn.ReLU(inplace=True),\n",
        "                    nn.Dropout2d(0.5)\n",
        "                )\n",
        "                self.conv_2 = nn.Sequential(\n",
        "                    nn.ConvTranspose2d(output_dim, output_dim, 5, 2, 0, 0),\n",
        "                    nn.BatchNorm2d(output_dim),\n",
        "                    nn.ReLU(inplace=True),\n",
        "                    nn.Dropout2d(0.5)\n",
        "                )\n",
        "            else:\n",
        "                self.conv_shortcut = nn.Sequential(\n",
        "                    #nn.Upsample(scale_factor=2),\n",
        "                    #nn.Conv2d(input_dim, output_dim, 3, 1, 1)\n",
        "                    nn.ConvTranspose2d(input_dim, output_dim, 5, 2, 1, 1),\n",
        "                    \n",
        "                )\n",
        "                self.conv_1 = nn.Sequential(\n",
        "                    nn.Conv2d(input_dim, output_dim, 3, 1, 1),\n",
        "                    nn.BatchNorm2d(output_dim),\n",
        "                    nn.ReLU(inplace=True),\n",
        "                    #nn.Dropout2d(0.5)\n",
        "                )\n",
        "                self.conv_2 = nn.Sequential(\n",
        "                    nn.ConvTranspose2d(output_dim, output_dim, 5, 2, 1, 1),\n",
        "                    nn.BatchNorm2d(output_dim),\n",
        "                    nn.ReLU(inplace=True),\n",
        "                    #nn.Dropout2d(0.5)\n",
        "                )\n",
        "\n",
        "        elif resample==None:\n",
        "            self.conv_shortcut = nn.Conv2d(input_dim, output_dim, 3, 1, 1)\n",
        "            self.conv_1 = nn.Sequential(\n",
        "                spectral_norm(nn.Conv2d(input_dim, output_dim, 3, 1, 1)),\n",
        "                nn.BatchNorm2d(output_dim),\n",
        "                nn.LeakyReLU(0.2, inplace=True)\n",
        "            )\n",
        "            self.conv_2 = nn.Sequential(\n",
        "                spectral_norm(nn.Conv2d(output_dim, output_dim, 3, 1, 1)),\n",
        "                nn.BatchNorm2d(output_dim),\n",
        "                nn.LeakyReLU(0.2, inplace=True)\n",
        "            )\n",
        "\n",
        "    def forward(self, input):\n",
        "        shortcut = self.conv_shortcut(input)\n",
        "        output = input\n",
        "        output = self.conv_1(output)\n",
        "        output = self.conv_2(output)\n",
        "\n",
        "        if self.input_dim != 8 * 64 and self.resample == \"down\":\n",
        "            output = self.leaky_relu(output)\n",
        "\n",
        "        return shortcut + output\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, in_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.dim = 64\n",
        "        self.label_emb = nn.Embedding(10, in_dim)\n",
        "        self.ln1 = nn.Linear(in_dim, self.dim * 8 * 1 * 1)\n",
        "        #self.rb1 = ResidualBlock(8 * self.dim, 8 * self.dim, resample = 'up')\n",
        "        self.rb1 = ResidualBlock(8 * self.dim, 4 * self.dim, resample = 'up')\n",
        "        self.rb2 = ResidualBlock(4 * self.dim, 2 * self.dim, resample = 'up')\n",
        "        self.rb3 = ResidualBlock(2 * self.dim, 1 * self.dim, resample = 'up', last=True)\n",
        "\n",
        "        self.conv_f = nn.Sequential(\n",
        "            nn.Conv2d(self.dim, 3, 3, 1, 1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "    \n",
        "    def forward(self, noise, labels):\n",
        "        embed = self.label_emb(labels)\n",
        "        output = torch.mul(embed, noise)\n",
        "        output = self.ln1(output)\n",
        "        output = output.view(-1, 8 * self.dim, 1, 1)\n",
        "        output = self.rb1(output)\n",
        "        output = self.rb2(output)\n",
        "        output = self.rb3(output)\n",
        "        #output = self.rb4(output)\n",
        "\n",
        "        output = self.conv_f(output)\n",
        "        return output\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self, in_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.dim = 64\n",
        "        self.rb1 = ResidualBlock(3, self.dim, resample = 'down')\n",
        "        self.rb2 = ResidualBlock(self.dim, 2 * self.dim, resample = 'down')\n",
        "        self.rb3 = ResidualBlock(2 * self.dim, 4 * self.dim, resample = 'down')\n",
        "        self.rb4 = ResidualBlock(4 * self.dim, 8 * self.dim, resample = None)\n",
        "        #self.rb5 = ResidualBlock(8 * self.dim, 8 * self.dim, resample = None)\n",
        "        #self.pool_f = spectral_norm(nn.Conv2d(8 * self.dim, 8 * self.dim, 4))\n",
        "\n",
        "        self.fc_source = nn.Linear(self.dim * 8 * 4 * 4, 1)\n",
        "        self.fc_class = nn.Linear(self.dim * 8 * 4 * 4, 10)\n",
        "        #self.sig = nn.Sigmoid()\n",
        "        #self.soft = nn.Softmax()\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = input\n",
        "        output = self.rb1(output)\n",
        "        output = self.rb2(output)\n",
        "        output = self.rb3(output)\n",
        "        output = self.rb4(output)\n",
        "        #output = self.rb5(output)\n",
        "        #output = self.pool_f(output)\n",
        "        output = output.view(output.size(0), self.dim * 8 * 4 * 4) \n",
        "        rf = self.fc_source(output)\n",
        "        c = self.fc_class(output)\n",
        "        return rf, c\n",
        "\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZmuGjQpdDOW"
      },
      "source": [
        "## Final Model (Summitted)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GTLdFVtyurc"
      },
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, in_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.label_emb = nn.Embedding(10, in_dim)\n",
        "\n",
        "        def layer(in_dim, out_dim):\n",
        "            return nn.Sequential(\n",
        "                nn.ConvTranspose2d(in_dim, out_dim, 5, 2, padding=0, output_padding=0, bias=False),\n",
        "                nn.BatchNorm2d(out_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout2d(0.5)\n",
        "            )\n",
        "        self.dim = 64\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(in_dim, self.dim * 8, bias=False),\n",
        "        )\n",
        "        \n",
        "        self.layer2 = layer(self.dim * 8, self.dim * 4)\n",
        "        self.layer3 = layer(self.dim * 4, self.dim * 2)\n",
        "        self.layer_final = nn.Sequential(\n",
        "            nn.ConvTranspose2d(self.dim * 2, 3, 5, 2, padding=1, output_padding=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.apply(weights_init)\n",
        "    \n",
        "    def forward(self, noise, labels):\n",
        "        embed = self.label_emb(labels)\n",
        "        x = torch.mul(embed, noise)\n",
        "        x = self.fc(x)\n",
        "        x = x.view(x.size(0), -1, 1, 1)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer_final(x)\n",
        "        return x\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            spectral_norm(nn.Conv2d(in_dim, 64, 3, 2, 1)), \n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            spectral_norm(nn.Conv2d(64, 64, 3, 1, 1)),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "        self.layer3 = nn.Sequential(\n",
        "            spectral_norm(nn.Conv2d(64, 128, 3, 2, 1)), \n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "        self.layer4 = nn.Sequential(\n",
        "            spectral_norm(nn.Conv2d(128, 128, 3, 1, 1)), \n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "        self.layer5 = nn.Sequential(\n",
        "            spectral_norm(nn.Conv2d(128, 256, 3, 2, 1)), \n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "        self.layer6 = nn.Sequential(\n",
        "            spectral_norm(nn.Conv2d(256, 256, 3, 1, 1)), \n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "        \n",
        "\n",
        "        self.fc_source = nn.Linear(256 * 4 * 4, 1, bias=False)\n",
        "        self.fc_class = nn.Linear(256 * 4 * 4, 10, bias=False)\n",
        "\n",
        "        self.apply(weights_init)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.layer5(x)\n",
        "        x = self.layer6(x)\n",
        "        x = x.view(x.size(0), 256 * 4 * 4)\n",
        "        rf = self.fc_source(x)\n",
        "        c = self.fc_class(x)\n",
        "        return rf, c\n",
        "\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cxo4teqaO5RJ"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EqomOouHezf"
      },
      "source": [
        "# Training hyperparameters\n",
        "batch_size = 64\n",
        "z_dim = 128\n",
        "\n",
        "z_sample = Variable(torch.randn(100, z_dim)).cuda()\n",
        "\n",
        "z_sample_label = []\n",
        "for i in range(10):\n",
        "    for j in range(10):\n",
        "        z_sample_label.append(i)\n",
        "z_sample_label = Variable(torch.LongTensor(z_sample_label)).cuda()\n",
        "\n",
        "lr = 2e-4\n",
        "\n",
        "n_epoch = 150\n",
        "n_critic = 5\n",
        "clip_value = 0.01\n",
        "lambda_gp = 10\n",
        "acgan_d_scale = 3\n",
        "acgan_g_scale = 1\n",
        "\n",
        "#log_dir = os.path.join(workspace_dir, 'logs')\n",
        "ckpt_dir = os.path.join(\"/content/\", 'checkpoints')\n",
        "#os.makedirs(log_dir, exist_ok=True)\n",
        "os.makedirs(ckpt_dir, exist_ok=True)\n",
        "\n",
        "# Model\n",
        "G = Generator(in_dim=z_dim).cuda()\n",
        "D = Discriminator(3).cuda()\n",
        "G.train()\n",
        "D.train()\n",
        "\n",
        "# Loss\n",
        "dis_criterion = nn.BCELoss()\n",
        "aux_criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "opt_D = torch.optim.Adam(D.parameters(), lr=lr, betas=(0, 0.9))\n",
        "opt_G = torch.optim.Adam(G.parameters(), lr=lr, betas=(0, 0.9))\n",
        "\n",
        "# DataLoader\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "sch_D = torch.optim.lr_scheduler.StepLR(opt_D, step_size=len(train_loader)*2, gamma=0.95)\n",
        "sch_G = torch.optim.lr_scheduler.StepLR(opt_G, step_size=len(train_loader)*2, gamma=0.95)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpJA1wzi0tii"
      },
      "source": [
        "### Training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GeDkuhR0sL8"
      },
      "source": [
        "steps = 0\n",
        "for e, epoch in enumerate(range(n_epoch)):\n",
        "    progress_bar = qqdm(train_loader)\n",
        "    for i, data in enumerate(progress_bar):\n",
        "        imgs, labels = data\n",
        "        imgs, labels = imgs.cuda(), labels.cuda()\n",
        "\n",
        "        bs = imgs.size(0)\n",
        "\n",
        "        #  Train D        \n",
        "        noise = Variable(torch.randn(bs, z_dim), requires_grad=False).cuda()\n",
        "        f_class = Variable(torch.LongTensor(np.random.randint(0, 10, bs)), requires_grad=False).cuda()\n",
        "        r_imgs = Variable(imgs).cuda()\n",
        "        f_imgs = G(noise, f_class)\n",
        "        r_class = Variable(labels).cuda()\n",
        "\n",
        "        # Forward\n",
        "        r_source, r_class_pred = D(r_imgs.detach())\n",
        "        f_source, f_class_pred = D(f_imgs.detach())\n",
        "\n",
        "        # Compute the loss for the discriminator.\n",
        "        r_c_loss = aux_criterion(r_class_pred, r_class)\n",
        "        f_c_loss = aux_criterion(f_class_pred, f_class)\n",
        "        C_loss_D = r_c_loss + f_c_loss\n",
        "\n",
        "        # WGAN Loss\n",
        "        loss_D = -torch.mean(r_source) + torch.mean(f_source)\n",
        "       \n",
        "        # Compute gradient penalty\n",
        "        alpha_g = torch.rand(r_imgs.size(0), 1, 1, 1).cuda().expand_as(r_imgs)\n",
        "        interpolated = Variable(alpha_g * r_imgs.data + (1 - alpha_g) * f_imgs.data, requires_grad=True)\n",
        "        out = D(interpolated)[0]\n",
        "\n",
        "        grad = torch.autograd.grad(outputs=out,\n",
        "            inputs=interpolated,\n",
        "            grad_outputs=torch.ones(out.size()).cuda(),\n",
        "            retain_graph=True,\n",
        "            create_graph=True,\n",
        "            only_inputs=True)[0]\n",
        "\n",
        "        grad = grad.view(grad.size(0), -1)\n",
        "        grad_l2norm = torch.sqrt(torch.sum(grad ** 2, dim=1))\n",
        "        d_loss_gp = torch.mean((grad_l2norm - 1) ** 2)\n",
        "\n",
        "        # Backward + Optimize\n",
        "        loss_D += lambda_gp * d_loss_gp\n",
        "        loss_D += acgan_d_scale * C_loss_D\n",
        "\n",
        "        D.zero_grad()\n",
        "        loss_D.backward()\n",
        "        opt_D.step()\n",
        "        sch_D.step()\n",
        "\n",
        "#---------------------------------------------------------------------------------------------------------------\n",
        "        #  Train G\n",
        "        if steps % n_critic == 0:\n",
        "            # fake images\n",
        "            for p in D.parameters():\n",
        "                p.requires_grad = False\n",
        "            for p in G.parameters():\n",
        "                p.requires_grad = True\n",
        "            \n",
        "            noise = Variable(torch.randn(bs, z_dim), requires_grad=False).cuda()\n",
        "            f_class = Variable(torch.LongTensor(np.random.randint(0, 10, bs)), requires_grad=False).cuda()\n",
        "\n",
        "            f_imgs = G(noise, f_class)\n",
        "            f_source, f_class_pred = D(f_imgs)\n",
        "            loss_G = -torch.mean(f_source) + acgan_g_scale * aux_criterion(f_class_pred, f_class)\n",
        "\n",
        "            G.zero_grad()\n",
        "            loss_G.backward()\n",
        "\n",
        "            # Update the generator.\n",
        "            opt_G.step()\n",
        "            sch_G.step()\n",
        "            \n",
        "            for p in D.parameters():\n",
        "                p.requires_grad = True\n",
        "            for p in G.parameters():\n",
        "                p.requires_grad = False\n",
        "\n",
        "        steps += 1\n",
        "        \n",
        "        progress_bar.set_infos({\n",
        "            'Loss_D': round(loss_D.item(), 4),\n",
        "            'Loss_G': round(loss_G.item(), 4),\n",
        "            'Epoch': e+1,\n",
        "            'Step': steps,\n",
        "        })\n",
        "\n",
        "    G.eval()\n",
        "    f_imgs_sample = (G(z_sample, z_sample_label).data + 1) / 2.0\n",
        "    \n",
        "    grid_img = torchvision.utils.make_grid(f_imgs_sample.cpu(), nrow=10)\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.imshow(grid_img.permute(1, 2, 0))\n",
        "    plt.show()\n",
        "    G.train()\n",
        "\n",
        "    if (e+1) % 5 == 0 or e == 0:\n",
        "        # Save the checkpoints.\n",
        "        torch.save(G.state_dict(), os.path.join(ckpt_dir, 'G.pth'))\n",
        "        torch.save(D.state_dict(), os.path.join(ckpt_dir, 'D.pth'))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXPXcVD_HJB2"
      },
      "source": [
        "### Load model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JnQdNx2SUS2"
      },
      "source": [
        "import torch\n",
        "z_dim = 128\n",
        "z_sample_label = []\n",
        "for i in range(100):\n",
        "    for j in range(10):\n",
        "        z_sample_label.append(j)\n",
        "z_sample_label = Variable(torch.LongTensor(z_sample_label)).cuda()\n",
        "\n",
        "G = Generator(z_dim)\n",
        "G.load_state_dict(torch.load(os.path.join(\"/content\", 'DLCV2_2.pth')))\n",
        "G.eval()\n",
        "G.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-I8PDocbHQiN"
      },
      "source": [
        "### Generate and show some images.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-SYKrRea_-Q"
      },
      "source": [
        "same_seeds(7414)\n",
        "# Generate 1000 images and make a grid to save them.\n",
        "n_output = 1000\n",
        "z_sample = Variable(torch.randn(n_output, z_dim)).cuda()\n",
        "imgs_sample = (G(z_sample, z_sample_label).data + 1) / 2.0\n",
        "\n",
        "# Show 32 of the images.\n",
        "grid_img = torchvision.utils.make_grid(imgs_sample[:100].cpu(), nrow=10)\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(grid_img.permute(1, 2, 0))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbcmoTQpz_yf"
      },
      "source": [
        "# Save the generated images.\n",
        "os.makedirs('output', exist_ok=True)\n",
        "for digit in range(10):\n",
        "    for num in range(100):\n",
        "        torchvision.utils.save_image(imgs_sample[num * 10 + digit], f'output/{digit}_{str(num+1).zfill(3)}.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzLw0hviyl7O"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def load_checkpoint(checkpoint_path, model):\n",
        "    state = torch.load(checkpoint_path, map_location = \"cuda\")\n",
        "    model.load_state_dict(state['state_dict'])\n",
        "    print('model loaded from %s' % checkpoint_path)\n",
        "\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "tfm = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMp9JuRdy6KA"
      },
      "source": [
        "import random\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "net = Classifier()\n",
        "path = \"Classifier.pth\"\n",
        "load_checkpoint(path, net)\n",
        "\n",
        "# GPU enable\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print('Device used:', device)\n",
        "if torch.cuda.is_available():\n",
        "    net = net.to(device)\n",
        "\n",
        "test_label = []\n",
        "for i in range(10):\n",
        "    for j in range(100):\n",
        "        test_label.append(i)\n",
        "test_label = Variable(torch.LongTensor(test_label)).cuda()\n",
        "\n",
        "test_path = \"/content/output/\"\n",
        "test_set = ImgDataset(test_path, test_label, tfm)\n",
        "test_loader = DataLoader(test_set, batch_size=1, num_workers=0, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "325axbTWjCBO"
      },
      "source": [
        "images = [(test_set[i][0]+1)/2 for i in range(100)]\n",
        "grid_img = torchvision.utils.make_grid(images, nrow=10)\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(grid_img.permute(1, 2, 0))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHWx0O56y_Gq"
      },
      "source": [
        "pred_count = 0\n",
        "progress_bar = qqdm(test_loader)\n",
        "for i, data in enumerate(progress_bar):\n",
        "    img, label = data\n",
        "    img, label = img.cuda(), label.cuda()\n",
        "\n",
        "    logit = net(img)\n",
        "    pred = logit.argmax(dim=-1)\n",
        "    if(pred == label):\n",
        "        pred_count += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDkI0d-12siE"
      },
      "source": [
        "pred_count"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}