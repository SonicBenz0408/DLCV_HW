{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ftag4T7Xof_K"
      },
      "outputs": [],
      "source": [
        "! /opt/bin/nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pK36nunY4eUY"
      },
      "outputs": [],
      "source": [
        "! git clone https://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@github.com/DLCV-Fall-2021/hw4-SonicBenz0408.git\n",
        "! bash ./hw4-SonicBenz0408/get_dataset.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GMO4LmfFDx_"
      },
      "outputs": [],
      "source": [
        "! pip install -r /content/hw4-SonicBenz0408/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.arange(0, 10, 2)"
      ],
      "metadata": {
        "id": "TKJFY0Vw70Gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6oxhq9Z426g"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def same_seeds(seed):\n",
        "    # Python built-in random module\n",
        "    random.seed(seed)\n",
        "    # Numpy\n",
        "    np.random.seed(seed)\n",
        "    # Torch\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "same_seeds(7414)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Re37W6DC9F4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.utils.data.sampler import Sampler\n",
        "\n",
        "import csv\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from PIL import Image\n",
        "filenameToPILImage = lambda x: Image.open(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOO0VOCl5pJR"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzfcASg_9yur"
      },
      "outputs": [],
      "source": [
        "def worker_init_fn(worker_id):                                                          \n",
        "    np.random.seed(np.random.get_state()[1][0] + worker_id)\n",
        "    \n",
        "# mini-Imagenet dataset\n",
        "class MiniDataset(Dataset):\n",
        "    def __init__(self, csv_path, data_dir):\n",
        "        self.data_dir = data_dir\n",
        "        self.data_df = pd.read_csv(csv_path).set_index(\"id\")\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            filenameToPILImage,\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "            ])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        path = self.data_df.loc[index, \"filename\"]\n",
        "        label = self.data_df.loc[index, \"label\"]\n",
        "        image = self.transform(os.path.join(self.data_dir, path))\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_df)\n",
        "\n",
        "class GeneratorSampler(Sampler):\n",
        "    def __init__(self, episode_file_path):\n",
        "        \n",
        "        episode_df = pd.read_csv(episode_file_path).set_index(\"episode_id\")\n",
        "        self.sampled_sequence = episode_df.values.flatten().tolist()\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(self.sampled_sequence) \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sampled_sequence)\n",
        "\n",
        "# total class / images per class\n",
        "# train : 64 / 600\n",
        "# val  : 16 / 600\n",
        "class PrototypicalBatchSampler(object):\n",
        "\n",
        "    def __init__(self, label_num_L, label_num_H, image_num, N_way, N_query, N_shot, eps_num):\n",
        "\n",
        "        super(PrototypicalBatchSampler, self).__init__()\n",
        "        self.label_num_L = label_num_L\n",
        "        self.label_num_H = label_num_H\n",
        "        self.label_num = self.label_num_H - self.label_num_L + 1\n",
        "        self.image_num = image_num\n",
        "        self.N_way = N_way\n",
        "        self.N_query = N_query\n",
        "        self.N_shot = N_shot\n",
        "        self.eps_num = eps_num\n",
        "\n",
        "        self.idxs = range(self.label_num)\n",
        "\n",
        "    def __iter__(self):\n",
        "\n",
        "        que = self.N_query\n",
        "        sup = self.N_shot\n",
        "        c_num = self.N_way\n",
        "\n",
        "        for it in range(self.eps_num):\n",
        "            batch = []\n",
        "            c_idxs = torch.randperm(self.label_num)[:c_num]\n",
        "            sample_idxs = []\n",
        "            for i, c in enumerate(c_idxs):\n",
        "                sample_idxs.append((torch.randperm(self.image_num)[:(sup + que)] + ((c + self.label_num_L) * self.image_num)).tolist())\n",
        "            for i in range(sup + que):\n",
        "                for j in range(c_num):\n",
        "                    batch.append(sample_idxs[j][i])\n",
        "            yield batch\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        return self.eps_num\n",
        "\n",
        "\n",
        "def euclidean_metric(a, b):\n",
        "    n = a.shape[0]\n",
        "    m = b.shape[0]\n",
        "    a = a.unsqueeze(1).expand(n, m, -1)\n",
        "    b = b.unsqueeze(0).expand(n, m, -1)\n",
        "    logits = -((a - b)**2).sum(dim=2)\n",
        "    return logits\n",
        "\n",
        "def cosine_similarity(a, b):\n",
        "    dot = torch.inner(a, b)\n",
        "    n = a.shape[0]\n",
        "    m = b.shape[0]\n",
        "    a = a.unsqueeze(1).expand(n, m, -1)\n",
        "    b = b.unsqueeze(0).expand(n, m, -1)\n",
        "    logits = dot / (torch.norm(a, dim=2) * torch.norm(b, dim=2))\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIYghreeoU-8"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5P8LGV5EBke"
      },
      "outputs": [],
      "source": [
        "class ProtoNetwork(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(ProtoNetwork, self).__init__()\n",
        "\n",
        "        self.conv_4 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(1600, 256),\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        features = self.conv_4(x)\n",
        "        features = features.view(features.shape[0], -1)\n",
        "        #features = self.mlp(features)\n",
        "\n",
        "        return features\n",
        "\n",
        "class Parametric(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Parametric, self).__init__()\n",
        "        \n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(5, 100),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100, 100),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100, 100),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100, 5),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.mlp(x)\n",
        "\n",
        "        return logits\n",
        "\n",
        "def distance(a, b):\n",
        "    n = a.shape[0]\n",
        "    m = b.shape[0]\n",
        "    a = a.unsqueeze(1).expand(n, m, -1)\n",
        "    b = b.unsqueeze(0).expand(n, m, -1)\n",
        "    logits = ((a - b)**2).sum(dim=2)\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P37_M-JXDbjT"
      },
      "outputs": [],
      "source": [
        "# hyperparameter\n",
        "train_way = 5 # p1-1 15\n",
        "test_way = 5\n",
        "N_shot = 10\n",
        "N_query = 15 # 20 43.29\n",
        "\n",
        "eps_num = 100 \n",
        "n_epoch = 100 # p1-1 150\n",
        "lr = 1e-3\n",
        "# loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = ProtoNetwork().cuda()\n",
        "#para_model = Parametric().cuda()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "#para_opt = torch.optim.Adam(para_model.parameters(), lr=lr)\n",
        "\n",
        "train_data_dir = \"/content/hw4_data/mini/train\"\n",
        "train_csv = \"/content/hw4_data/mini/train.csv\"\n",
        "val_data_dir = \"/content/hw4_data/mini/val\"\n",
        "val_csv = \"/content/hw4_data/mini/val.csv\"\n",
        "test_data_dir = \"/content/hw4_data/mini/val\"\n",
        "test_csv = \"/content/hw4_data/mini/val_testcase.csv\"\n",
        "\n",
        "train_dataset = MiniDataset(train_csv, train_data_dir)\n",
        "val_dataset = MiniDataset(val_csv, val_data_dir)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset, batch_sampler=PrototypicalBatchSampler(0, 47, 600, train_way, N_query, N_shot, eps_num),\n",
        "    num_workers=0, pin_memory=True, worker_init_fn=worker_init_fn)\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    train_dataset, batch_sampler=PrototypicalBatchSampler(48, 63, 600, test_way, N_query, N_shot, eps_num),\n",
        "    num_workers=0, pin_memory=True, worker_init_fn=worker_init_fn)\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    val_dataset, batch_size=test_way * (N_query + N_shot),\n",
        "    num_workers=2, pin_memory=False, worker_init_fn=worker_init_fn,\n",
        "    sampler=GeneratorSampler(test_csv))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UZnK6PeOLYW"
      },
      "outputs": [],
      "source": [
        "print(abs_dist.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qN8Yglc1gw3T"
      },
      "outputs": [],
      "source": [
        "best_acc = 0.\n",
        "\n",
        "for epoch in range(n_epoch):\n",
        "    \n",
        "    train_loss, val_loss, val_acc = 0., 0., 0.\n",
        "\n",
        "    model.train()\n",
        "    #para_model.train()\n",
        "    for i, (data, target) in enumerate(train_loader):\n",
        "\n",
        "        support_input = data[:train_way * N_shot,:,:,:].cuda()\n",
        "        query_input  = data[train_way * N_shot:,:,:,:].cuda()\n",
        "\n",
        "        label = torch.arange(train_way).repeat(N_query)\n",
        "        label = label.type(torch.cuda.LongTensor)\n",
        "\n",
        "        protos = model(support_input)\n",
        "        protos = protos.reshape(N_shot, train_way, -1).mean(dim=0)\n",
        "\n",
        "        logits = euclidean_metric(model(query_input), protos)\n",
        "        #logits = cosine_similarity(model(query_input), protos)\n",
        "        #abs_dist = distance(model(query_input), protos)\n",
        "        #logits = para_model(abs_dist)\n",
        "        \n",
        "        loss = criterion(logits, label)\n",
        "        \n",
        "        train_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        #para_opt.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        #para_opt.step()\n",
        "    \n",
        "    model.eval()\n",
        "    #para_model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, (data, target) in enumerate(val_loader):\n",
        "\n",
        "            support_input = data[:test_way * N_shot,:,:,:].cuda()\n",
        "            query_input  = data[test_way * N_shot:,:,:,:].cuda()\n",
        "\n",
        "            label = torch.arange(test_way).repeat(N_query)\n",
        "            label = label.type(torch.cuda.LongTensor)\n",
        "\n",
        "            protos = model(support_input)\n",
        "            protos = protos.reshape(N_shot, test_way, -1).mean(dim=0)\n",
        "\n",
        "            logits = euclidean_metric(model(query_input), protos)\n",
        "            #logits = cosine_similarity(model(query_input), protos)\n",
        "            #abs_dist = distance(model(query_input), protos)\n",
        "            #logits = para_model(abs_dist)\n",
        "            \n",
        "            loss = criterion(logits, label)\n",
        "            acc = (logits.argmax(dim=1) == label).float().mean()\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            val_acc += acc.item()\n",
        "    \n",
        "    train_loss /= len(train_loader) \n",
        "    val_loss /= len(val_loader)\n",
        "    val_acc /= len(val_loader)\n",
        "    print(f'epoch:{epoch+1}, train_loss: {train_loss:.4f}, val_loss: {val_loss:.4f}, acc: {val_acc:.4f}')\n",
        "    \n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        print(\"save best model with acc\", best_acc)\n",
        "        torch.save(model.state_dict(), \"/content/model.ckpt\")\n",
        "        #torch.save(para_model.state_dict(), \"/content/para.ckpt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agivrbwTBHBS"
      },
      "outputs": [],
      "source": [
        "a = [1, 2, 3]\n",
        "a += [2, 3, 4]\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQOoocio-ABk"
      },
      "outputs": [],
      "source": [
        "! python3 /content/hw4-SonicBenz0408/test_testcase.py \\\n",
        "    --N-shot 10 \\\n",
        "    --N-query 15 \\\n",
        "    --load /content/model.ckpt \\\n",
        "    --test_csv /content/hw4_data/mini/val.csv \\\n",
        "    --test_data_dir /content/hw4_data/mini/val \\\n",
        "    --testcase_csv /content/hw4_data/mini/val_testcase.csv \\\n",
        "    --output_csv /content/output.csv \\\n",
        "    #--para_load /content/para.ckptx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lv0V8YtMSaFu"
      },
      "outputs": [],
      "source": [
        "! python3 /content/hw4-SonicBenz0408/eval.py /content/p1_out.csv /content/hw4_data/mini/val_testcase_gt.csv"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "DLCV_HW4-1",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}